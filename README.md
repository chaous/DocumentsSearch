# отчет: Проектирование ML-системы — Задание 10
### Курс Проектирование систем машинного обучения
### Студент: Илья Рожков Алексеевич
### Группа: МЛ-2025

# Введение и постановка задачи
Проектируется система для семантического поиска по внутренним корпоративным документам крупной организации.
Система должна обеспечивать быстрый и точный поиск по отчётам, презентациям, внутренним вики-страницам и другим источникам знаний, используя векторный поиск на основе заранее рассчитанных эмбеддингов документов.
Обработка запроса пользователя должна выполняться без обращения к тяжёлым генеративным моделям в режиме онлайн: используются компактные модели для получения эмбеддингов запросов и оптимизированный векторный индекс. Поиск должен учитывать сложную модель прав доступа, чтобы каждый пользователь видел только те документы, к которым у него есть разрешение.
Система должна работать под высокой нагрузкой и масштабироваться под большое количество пользователей в корпорации.



# Бизнес-цели
- 1. **Почти мгновенный доступ к информации**
Сократить среднее время поиска внутренних документов (регламентов, отчётов, презентаций, вики-страниц) с нескольких минут до **долей секунды** благодаря высокопроизводительному семантическому поиску с задержкой не более **417 мс**.
Это **повышает скорость принятия решений** и **снижает операционные задержки** в работе сотрудников.
- 2. **Улучшение релевантности результатов поиска**
Повысить точность и полезность выдачи за счёт использования мл поиска, чтобы сотрудники находили **нужные документы с первого запроса**.
Цель — уменьшить количество повторных запросов и повысить эффективность работы.
- 3. **Поддержка большого числа пользователей без деградации качества**
Обеспечить стабильную работу системы для **1,288,472 DAU** и **пиковых 16,994 RPS**, сохраняя высокую скорость и релевантность поиска.
Это снижает нагрузку на внутренние службы поддержки и повышает вовлечённость пользователей в использование корпоративного хранилища знаний.


**Требования к системе:**
- Задержка (latency) ответа не должна превышать **417 мс**.
- Система должна обслуживать **1,288,472 активных пользователей в день (DAU)**, с пиковой нагрузкой в **16,994 запросов в секунду (RPS)**.
- Система должна быть масштабируемой и отказоустойчивой.



# Часть 1: Формулировка ML-задачи и выбор модели
- **1. Определение ML-задачи**
Задачу можно сформулировать как задачу ранжирования документов (Learning-to-Rank) в рамках семантического поиска.
Для каждого пользовательского запроса система должна упорядочить набор доступных пользователю документов по степени их релевантности.
Поиск выполняется с учётом семантического сходства между запросом и документами, а также ограничений доступа (пользователь может видеть только разрешённые документы).


## Входные данные:
Текстовый запрос пользователя на естественном языке.
Корпус внутренних документов (отчёты, презентации, вики), представленных в виде текстовых фрагментов.
Метаданные документов:
идентификаторы проектов и команд;
информация о правах доступа (ACL / RBAC);
тип документа, дата создания и версия.
Выходные данные:
Упорядоченный список документов (или фрагментов документов), релевантных запросу пользователя.
Для каждого документа — числовой скор релевантности.


## Целевая переменная:
Целевой переменной является оценка релевантности документа запросу.
В явном виде она может отсутствовать, поэтому используется одна из следующих форм:
- Неявная обратная связь пользователей:
- клики по результатам поиска;
- время просмотра документа;
- повторные запросы.
## Слабая разметка:
- бинарная метка релевантности (релевантен / нерелевантен);
- порядковая оценка (например, 0 — нерелевантен, 1 — частично релевантен, 2 — релевантен).
## Прокси-таргет:
- Семантическое сходство между эмбеддингом запроса и эмбеддингом документа, используемое как обучающий сигнал.
- Таким образом, задача не предполагает существование «идеального ответа», а оптимизируется по метрикам качества ранжирования (Precision@k, recal@K).



# 2. Выбор модели
Рассмотрим два подхода к построению системы семантического поиска по внутренним корпоративным документам.
## Подход 1: Прямой семантический поиск по эмбеддингам (Vector Similarity Search)
В данном подходе каждый документ и пользовательский запрос представляются в виде векторных эмбеддингов, полученных с помощью компактной нейросетевой модели.
Поиск осуществляется путём вычисления близости между эмбеддингом запроса и эмбеддингами документов с использованием приближённого поиска ближайших соседей (Approximate Nearest Neighbors).
### Преимущества:
- Очень высокая скорость поиска, что позволяет уложиться в ограничение по задержке 417 мс.
- Простая и хорошо масштабируемая архитектура.
- Возможность предварительного вычисления эмбеддингов документов оффлайн.
- Минимальные вычислительные затраты в режиме онлайн.
### Недостатки:
- Релевантность определяется только локальным сходством запроса и документа.
- Не учитываются глобальные связи между документами (темы, контекст, совместное использование).
- Сложно улучшать качество без увеличения размерности эмбеддингов или сложности модели.
## Подход 2: Семантический поиск с использованием графа документов на основе эмбеддингов
В данном подходе документы представляются в виде вершин графа, а рёбра формируются оффлайн на основе семантической близости их эмбеддингов (например, по k-ближайшим соседям).
Граф документов строится заранее на этапе подготовки данных и отражает семантические связи между документами.
В процессе поиска выполняется быстрый векторный retrieval для получения начального набора кандидатов, после чего используется навигация по предварительно построенному графу документов для уточнения и дополнения списка релевантных результатов.
### Преимущества:
- Более высокая релевантность за счёт учёта глобальной структуры корпуса документов.
- Возможность находить связанные документы, которые не являются ближайшими по векторному сходству.
- Улучшение качества поиска без использования тяжёлых моделей в режиме онлайн.
- Возможность объяснять результаты поиска через связи в графе.
- Навигация по графу позволяет ограничить пространство поиска и сократить количество проверяемых документов по сравнению с полным перебором.
### Недостатки:
- Более сложная оффлайн-подготовка данных (построение и обновление графа).
- Дополнительные затраты памяти на хранение графовой структуры.
- Усложнение логики поиска по сравнению с прямым ANN.
## Выбор модели
Для данной задачи выбирается семантический поиск с использованием графа документов, построенного на основе эмбеддингов.
Несмотря на более сложную подготовку данных, данный подход позволяет существенно повысить релевантность результатов поиска, сохранив при этом высокую скорость работы.
Отсутствие тяжёлых моделей в режиме онлайн и возможность параллельной обработки запросов позволяют надёжно уложиться в требование по задержке 417 мс и обеспечить масштабируемость системы при высокой нагрузке.

# Часть 2: Проектирование архитектуры

## 1. Высокоуровневая архитектура системы

Высокоуровневая архитектура показывает взаимодействие основных компонентов
системы внутреннего семантического поиска: от сбора и обработки документов
до развертывания поискового сервиса и мониторинга качества и
производительности. Система должна обеспечивать быстрый поиск (не более
417 мс) при высокой нагрузке и строго соблюдать контроль доступа
к документам.

Ключевые компоненты:

- **Document Sources**:
Корпоративные источники данных: файловые хранилища
(SharePoint, сетевые диски), корпоративная вики (Confluence),
базы отчетов и презентаций, внутренние порталы.

- **Ingestion Service (Connectors)**:
Набор сервисов для регулярного извлечения документов и метаданных
(версия, автор, дата, проект, ссылки, права доступа).

- **Preprocessing & Chunking**:
Сервис предобработки документов, включающий извлечение текста из
PDF, DOCX, PPTX и HTML, очистку данных и разбиение документов
на фрагменты (чанки) для повышения точности поиска.

- **Embedding Service (Offline):**
Сервис вычисления эмбеддингов документов и чанков в режиме оффлайн
по расписанию или при обновлении данных.

- **Vector Index (ANN Store):**
Векторное хранилище с поддержкой приближенного поиска ближайших
соседей (ANN), обеспечивающее быстрый retrieval кандидатов
по эмбеддингу запроса.

- **Document Graph Store:**
Хранилище графа документов, построенного оффлайн на основе
семантической близости эмбеддингов (k-ближайших соседей).
Используется для навигации и расширения результатов поиска.

- **Access Control Service (ACL/RBAC):**
Сервис контроля доступа, интегрированный с корпоративной системой
аутентификации и авторизации (SSO / IAM). Обеспечивает фильтрацию
документов в соответствии с правами пользователя.

- **Search API (Inference / Serving):**
Основной поисковый сервис, который выполняет:
- получение текстового запроса пользователя;
- вычисление эмбеддинга запроса;
- первичный поиск кандидатов в Vector Index;
- навигацию по графу документов;
- фильтрацию по правам доступа;
- ранжирование и возврат результатов поиска.
Сервис развёртывается в Kubernetes и масштабируется
горизонтально для обслуживания пиковых 16 994 RPS.

- **Metadata Store:**
База данных для хранения метаданных документов
(названия, ссылки, версии, владельцы, теги).

- **User Interface:**
Корпоративный веб-интерфейс поиска, через который пользователи
выполняют запросы и получают результаты поиска.

- **Monitoring & Logging:**
Система мониторинга и логирования для отслеживания
производительности (latency, RPS, ошибки), качества поиска
и аудита доступа.
Инструменты: Prometheus, Grafana, централизованное логирование.

- **Training & Evaluation Pipeline:**
Конвейер обучения и оценки моделей эмбеддингов и параметров поиска
на основе логов пользовательского поведения и обратной связи. (не первая итерация)

![Высокоуровневая архитектура системы](high_level_architecture.png)


## Архитектура Data Pipeline

Data Pipeline описывает процесс сбора и подготовки данных для системы
семантического поиска по корпоративным документам. Пайплайн выполняется
оффлайн и обеспечивает обновление индексов и графа документов.

Этапы:

1. **Сбор данных:**
Коннекторы извлекают документы из корпоративных источников
(SharePoint/файловые хранилища, Wiki/Confluence, порталы), а также
метаданные и права доступа (ACL/RBAC).
Для документов с высоким приоритетом (например, регламенты безопасности,
оперативные инструкции, срочные объявления) используется событийное
обновление: при изменении документа автоматически запускается
переиндексация и обновление эмбеддингов.
Для остальных документов применяется периодическое обновление по
расписанию (batch-обработка), что позволяет снизить нагрузку на систему
и оптимизировать использование ресурсов.

2. **Архивирование:**
Сырые документы сохраняются в централизованное хранилище
(например, S3/HDFS/объектное хранилище) для аудита и повторной обработки.

3. **Предобработка:**
Извлекается текст из PDF/DOCX/PPTX/HTML, выполняется очистка и разбиение
на фрагменты (чанки). Параллельно извлекаются изображения и подписи
(если присутствуют: диаграммы, схемы, скриншоты).

4. **Построение эмбеддингов:**
Для текстовых чанков оффлайн вычисляются эмбеддинги с помощью
предобученной Transformer-модели (например, BERT-подобной модели для
sentence embeddings).
Для изображений (если они важны) вычисляются визуальные эмбеддинги
(например, CLIP/Vision Transformer), после чего они объединяются с
текстовыми эмбеддингами (раннее или позднее объединение) и сохраняются
как мультимодальные представления документа/чанка.

5. **Индексация:**
Эмбеддинги добавляются в векторный индекс (ANN), который обеспечивает
быстрый retrieval top-K кандидатов по запросу.

6. **Построение графа документов:**
На основе эмбеддингов оффлайн формируется граф документов/чанков,
где рёбра отражают семантическую близость (например, k-ближайших
соседей). Граф используется для расширения и уточнения результатов поиска.

7. **Хранилища:**
- Vector Store: хранение эмбеддингов и ANN-индекса
- Graph Store: хранение графа документов
- Metadata Store: хранение метаданных и ссылок на оригинальные документы

### Примечание:
На старте обучение моделей не выполняется — используются предобученные
модели эмбеддингов. <!--Пайплайн регулярно обновляет индекс и граф при
появлении новых документов или изменении прав доступа. -->

![Архитектура Data Pipeline](data_pipeline.png)


## Архитектура Inference Pipeline (Serving)

Inference Pipeline описывает онлайн-контур обработки пользовательских запросов
к системе внутреннего семантического поиска. Контур ориентирован на высокую
пропускную способность и малую задержку ответа (не более **417 мс**) при
пиковой нагрузке до **16 994 RPS**, а также на строгий контроль доступа к данным.

Компоненты:

- **API Gateway / Load Balancer:**
  Принимает поисковые запросы от пользовательского интерфейса (веб-портал),
  выполняет аутентификацию, TLS termination, rate limiting и распределяет нагрузку
  между репликами Search API.

- **Search API (Inference Service) в Kubernetes:**
  Основной сервис обработки запроса:
  1) нормализация и парсинг запроса,
  2) вычисление эмбеддинга запроса,
  3) быстрый ANN-retrieval top-K кандидатов из векторного индекса,
  4) расширение кандидатов с использованием графа документов (опционально),
  5) фильтрация по правам доступа (ACL/RBAC),
  6) финальное ранжирование и формирование ответа (сниппеты, ссылки, метаданные).

- **Query Embedding Runtime:**
  Сервис вычисления эмбеддинга запроса на основе предобученной
  Transformer-модели (BERT-подобной). Для снижения задержек применяются
  оптимизации (батчинг, кэширование, ONNX/TensorRT при необходимости).
  Обучение моделей в онлайн-контуре не выполняется.

- **Vector Index (ANN Store):**
  Векторный индекс для быстрого поиска ближайших эмбеддингов документов/чанков.
  Индекс шардируется и реплицируется для обеспечения масштабируемости и
  отказоустойчивости при высоком RPS.

- **Document Graph Store (k-NN граф):**
  Хранилище семантического графа документов, используемого для расширения
  и уточнения результатов поиска, повышения полноты и устойчивости выдачи.

- **Metadata Store:**
  Хранилище метаданных документов (заголовки, версии, теги, ссылки), используемое
  для генерации человекочитаемого ответа пользователю.

- **Access Control Service (SSO / IAM, ACL / RBAC):**
  Сервис проверки прав доступа пользователя. Гарантирует, что в выдачу
  попадают только документы, доступные конкретному пользователю или группе.
  Поддерживается аудит обращений к защищённым данным.

- **Redis Cache:**
  Кэширует популярные запросы и промежуточные результаты (эмбеддинги запроса,
  результаты ANN-retrieval) для снижения нагрузки и уменьшения latency.
  Используется короткий TTL и инвалидация при изменении документов или прав доступа.

- **HPA:**
  Автоматическое масштабирование реплик Search API и сервиса эмбеддингов
  на основе метрик CPU/GPU, RPS и p95/p99 latency.

- **Эксперименты: A/B-тесты и многоуровневые бандиты**
  
  - **A/B-тестирование (для важных изменений):**
    Используется для изменений, которые потенциально влияют на ключевые свойства
    системы (релевантность поиска, корректность фильтрации по ACL/RBAC, стабильность
    и задержку). Примеры: новая модель эмбеддингов, изменение схемы retrieval
    (ANN параметров), новая логика ранжирования, изменения в фильтрации по правам.
    Запуск осуществляется через строго контролируемые эксперименты (A/B) с
    фиксированным разбиением трафика и проверкой guardrail-метрик:
    p95/p99 latency, error rate, доля пустых результатов, жалобы пользователей,
    показатели вовлечённости (CTR/дальнейшие клики), а также аудит корректности ACL.

  - **Многоуровневые бандиты / Contextual Bandits (для не критичных улучшений):**
    Применяются для локальных UX- и UI-улучшений, которые не должны влиять на
    безопасность и базовую корректность выдачи. Примеры: порядок отображения блоков,
    формат сниппета, подсветка, варианты автодополнения, лёгкие эвристики
    переранжирования в пределах уже разрешённого набора результатов.
    Бандиты позволяют автоматически выбирать лучший вариант на основе
    пользовательской обратной связи (например, CTR, dwell time, успешное открытие
    документа) и технических метрик (например, latency/cost), ускоряя оптимизацию
    без необходимости длительных фиксированных A/B для каждой мелкой правки.


- **Monitoring & Logging (Prometheus / Grafana / Log Storage):**
  Сбор метрик (latency p50/p95/p99, RPS, error rate, cache hit rate),
  централизованное логирование и алертинг при деградации качества сервиса.


![Архитектура Inference Pipeline](inference_pipeline.png)